{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!unzip twitter.zip",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Archive:  twitter.zip\n   creating: twitter/\n  inflating: twitter/twitter-test-neg.txt  \n  inflating: twitter/twitter-test-pos.txt  \n  inflating: twitter/twitter-train-neg.txt  \n  inflating: twitter/twitter-train-pos.txt  \n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def openfile(filename):\n    word_list = []\n    f = open(filename)\n    for line in f:\n      word_list.append(line)\n    return word_list\n\ntrain_pos = []\ntrain_neg = []\ntest_pos = []\ntest_neg = []\ntrain_pos = openfile(\"twitter/twitter-train-pos.txt\")\ntrain_neg = openfile(\"twitter/twitter-train-neg.txt\")\ntest_pos = openfile(\"twitter/twitter-test-pos.txt\")\ntest_neg = openfile(\"twitter/twitter-test-neg.txt\")\n\n",
      "execution_count": 48,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\ntrain_pos_df = pd.DataFrame(train_pos,columns = [\"text\"])\ntrain_neg_df = pd.DataFrame(train_neg,columns = [\"text\"])\ntest_pos_df = pd.DataFrame(test_pos,columns = [\"text\"])\ntest_neg_df = pd.DataFrame(test_neg,columns = [\"text\"])\n\ntrain_pos_df=train_pos_df.fillna(\"\")\ntrain_neg_df=train_neg_df.fillna(\"\")\ntest_pos_df=test_pos_df.fillna(\"\")\ntest_neg_df=test_neg_df.fillna(\"\")\n\n\nprint(train_pos_df.head())",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": "                                                text\n0               Juuuuuuuuuuuuuuuuussssst Chillin!!\\n\n1         hmmmm.... i wonder how she my number @-)\\n\n2  Feeling strangely fine. Now I'm gonna go liste...\n3                                \"   goodbye exams\\n\n4  (: !!!!!! - so i wrote something last week. an...\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\nones = [1 for val in range(train_pos_df.shape[0])]\ntrain_pos_df[\"label\"] = ones \nones = [1 for val in range(test_pos_df.shape[0])]\ntest_pos_df[\"label\"] = ones \n\nzeros = [0 for val in range(train_neg_df.shape[0])]\ntrain_neg_df[\"label\"] = zeros\nzeros = [0 for val in range(test_neg_df.shape[0])]\ntest_neg_df[\"label\"] = zeros\n\nprint(train_pos_df.head())\nprint(train_neg_df.head())",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": "                                                text  label\n0               Juuuuuuuuuuuuuuuuussssst Chillin!!\\n      1\n1         hmmmm.... i wonder how she my number @-)\\n      1\n2  Feeling strangely fine. Now I'm gonna go liste...      1\n3                                \"   goodbye exams\\n      1\n4  (: !!!!!! - so i wrote something last week. an...      1\n                                                text  label\n0                 I missed the New Moon trailer...\\n      0\n1     i think mi bf is cheating on me!!!       T_T\\n      0\n2  Sunny Again        Work Tomorrow  :-|       TV...      0\n3                   this weekend has sucked so far\\n      0\n4                             ok thats it you win.\\n      0\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "train_df = pd.concat([train_pos_df, train_neg_df])\ntest_df = pd.concat([test_pos_df, test_neg_df])\n\nprint(train_df.shape)\nprint(test_df.columns)",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(750007, 2)\nIndex(['text', 'label'], dtype='object')\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import nltk\nnltk.download(\"stopwords\")\nnltk.download(\"wordnet\")",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[nltk_data] Downloading package stopwords to /home/nbuser/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /home/nbuser/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 53,
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import string\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\ndef clean_text(text):\n        text = text.lower()\n        text = [word.strip(string.punctuation) for word in text.split()]\n        text = [word for word in text if not any(c.isdigit() for c in word)]\n        stop = stopwords.words(\"english\")\n        text = [word for word in text if word not in stop]\n        text = [word for word in text if len(word) > 0]\n        lemma = WordNetLemmatizer()\n        text = [lemma.lemmatize(word) for word in text]\n        text = [word for word in text if len(word) > 1]\n        text = \" \".join(text)\n        return text\n\ntrain_df[\"clean_text\"] = train_df[\"text\"].apply(lambda x:clean_text(x))\ntest_df[\"clean_text\"] = test_df[\"text\"].apply(lambda x:clean_text(x))\n\nprint(train_df.head())\nprint(test_df.head())",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": "                                                text  label  \\\n0               Juuuuuuuuuuuuuuuuussssst Chillin!!\\n      1   \n1         hmmmm.... i wonder how she my number @-)\\n      1   \n2  Feeling strangely fine. Now I'm gonna go liste...      1   \n3                                \"   goodbye exams\\n      1   \n4  (: !!!!!! - so i wrote something last week. an...      1   \n\n                                          clean_text  \n0                   juuuuuuuuuuuuuuuuussssst chillin  \n1                                hmmmm wonder number  \n2  feeling strangely fine i'm gonna go listen sem...  \n3                                       goodbye exam  \n4  wrote something last week got call someone new...  \n                                                text  label  \\\n0                          omg its already 7:30 :O\\n      1   \n1  handed in my uniform today . i miss you already\\n      1   \n2  thanks to all the haters up in my face all day...      1   \n3  You're the only one who can see this cause no ...      1   \n4                 uploading pictures on friendster\\n      1   \n\n                                        clean_text  \n0                                      omg already  \n1                handed uniform today miss already  \n2                            thanks hater face day  \n3  one see cause one else following pretty awesome  \n4                     uploading picture friendster  \n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n\ntokenizer = CountVectorizer(analyzer='word')\ntokenizer.fit(train_df[\"clean_text\"])\n\nx_train = tokenizer.transform(train_df[\"clean_text\"])\nx_valid = tokenizer.transform(test_df[\"clean_text\"])",
      "execution_count": 68,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.linear_model  import LogisticRegression \nfrom sklearn.metrics import f1_score\n\nlr = LogisticRegression()\nlr.fit(x_train, train_df[\"label\"])\n\nprint(f1_score(test_df[\"label\"], lr.predict(x_valid)))",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": "0.7548678591322646\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}